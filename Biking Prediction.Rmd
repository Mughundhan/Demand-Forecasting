---
title: "Bike Sharing Demand"
author: "Mughundhan Chandrasekar"
date: "9/25/2017"
output:
  word_document: default
  html_document: default
---

####1. About the Project
Bike sharing systems are a means of renting bicycles where the process of obtaining membership, rental, and bike return is automated via a network of kiosk locations throughout a city. Using these systems, people are able rent a bike from one location and return it to a different place on an as-needed basis.

The data generated by these systems makes them attractive for researchers because the **duration of travel, departure location, arrival location, and time elapsed** is explicitly recorded. Bike sharing systems therefore function as a sensor network, which can be used for studying mobility in a city. In this competition, participants were asked to ***combine historical usage patterns with weather data in order to forecast bike rental demand*** in the Capital Bikeshare program in Washington, D.C.

The project aims to Forecast the use of a city bikeshare system i.e. to ***predict the total count of bikes rented during each hour*** covered by the test set.

Kaggle Score: 0.40812
Ranking
```{r error=FALSE, message=FALSE, echo=FALSE}
Number_of_Participants <- 3252
Kaggle_Score <- 0.40812
Kaggle_Rank <- 311
Among_Top_Percentile <- 311/3252
cbind(Kaggle_Score, Number_of_Participants, Kaggle_Rank, Among_Top_Percentile)
```
####2. Hypotheses Generation

- **Hourly trend**: There must be high demand during office timings. Early morning and late evening can have different trend (cyclist) and low demand during 10:00 pm to 4:00 am.

- **Daily Trend**: Registered users demand more bike on weekdays as compared to weekend or holiday.

- **Rain**: The demand of bikes will be lower on a rainy day as compared to a sunny day. Similarly, higher humidity will cause to lower the demand and vice versa.

- **Temperature**: In India, temperature has negative correlation with bike demand. But, after looking at Washington???s temperature graph, I presume it may have positive correlation.

- **Pollution**: If the pollution level in a city starts soaring, people may start using Bike (it may be influenced by government / company policies or increased awareness).

- **Time**: Total demand should have higher contribution of registered user as compared to casual because registered user base would increase over time.

- **Traffic**: It can be positively correlated with Bike demand. Higher traffic may force people to use bike as compared to other road transport medium like car, taxi etc

####3. About the Dataset

#####3.1. Independent Variables

1. **datetime**:   date and hour in "mm/dd/yyyy hh:mm" format
2. **season**:     Four categories-> 1 = spring, 2 = summer, 3 = fall, 4 = winter
3. **holiday**:    whether the day is a holiday or not (1/0)
4. **workingday**: whether the day is neither a weekend nor holiday (1/0)
5. **weather**:    Four Categories of weather
             1-> Clear, Few clouds, Partly cloudy, Partly cloudy
             2-> Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist
             3-> Light Snow and Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds
             4-> Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog
6. **temp**:       hourly temperature in Celsius
7. **atemp**:      "feels like" temperature in Celsius
8. **humidity**:   relative humidity
9. **windspeed**:  wind speed

#####3.2. Dependent Variables

10. **registered**: number of registered user
11. **casual**:     number of non-registered user
12. **count**:      number of total rentals (registered + casual)


####4. Creating an appropriate Environment

```{r warning=FALSE, message=FALSE}
rm(list = ls())
setwd('/Users/Mughundhan/Analytics Vidhya/Rental Biking')
library(lubridate) # for csv files
library(leaflet)   # interactive maps
library(dplyr)     # for piping purpose %>%
#library(rCharts)   # route-map
#library(rMaps)     # route-map
library(data.table)# aggregate
library(ggplot2)   # barplot
library(mice)      # imputing with plausible data values (drawn from a distribution specifically designed for each missing datapoint)
#install.packages("rCharts", "rMaps", "data.table", "ggplot2", "mice")
#install.packages("rattle", dep=c("Suggests"))
library(rpart)     #Decision Tree Model
#library(rattle)    #Good visual plot for the decision tree model. 
library(rpart.plot)
library(RColorBrewer)
library(MASS)      #Random Forest
library(randomForest)
library(corrplot) #Informative Correlation Plot

train <- read.csv("train.csv", header=T, na.strings=c("","NA")) #Empty spaces to be replaced by NA
test <- read.csv("test.csv", header=T, na.strings=c("","NA"))
```

####5. Basic Data Exploration

#####5.1. Combining both test and train dataset and Identify final structure.

Add or remove columns to adjust the structure of dataset in-order to facilitate the join.

```{r warning=FALSE, message=FALSE}
test$registered=0
test$casual=0
test$count=0
fdata=rbind(train,test)
str(fdata)
```

#####5.2. Identify Missing Values

```{r warning=FALSE, message=FALSE, echo=FALSE}
sapply(fdata, function(x) sum(is.na(x))) #Number of Missing Values in each column
table(is.na(fdata))
```

######Observation: There are no missing values in the dataset

#####5.3. Understand Patterns

```{r warning=FALSE, message=FALSE}
par(mfrow=c(4,2)) #Fill by rows: Row, Cols
par(mar = rep(2, 4)) #Setting Margins
hist(fdata$season, col="blue")
hist(fdata$weather, col="yellow")
hist(fdata$humidity, col="green")
hist(fdata$holiday, col="violet")
hist(fdata$workingday, col="brown")
hist(fdata$temp, col="red")
hist(fdata$atemp, col="purple")
hist(fdata$windspeed, col="pink")
```

######Observation:

1. **Season** has four categories
2. **Weather-1** contributes the highest
3. Variables *temp, atemp, humidity and windspeed*  looks naturally distributed.
4. Deeper look required in working day and holiday to understand the distribution

#####5.4. Identify the Proportion

```{r warning=FALSE, message=FALSE}
prop.table(table(fdata$weather))
prop.table(table(fdata$holiday))
prop.table(table(fdata$workingday))
```

#####5.5. Type-Casting

```{r warning=FALSE, message=FALSE}
fdata$season=as.factor(fdata$season)
fdata$weather=as.factor(fdata$weather)
fdata$holiday=as.factor(fdata$holiday)
fdata$workingday=as.factor(fdata$workingday)
```


####6. Multi-Variate Analysis

This can also be considered as Hypotheses Testing.

#####6.1. Hourly Trend - Bike Usage

Partitioning data as follows:

1. Train <- First 19 days of every month
2. Test <- Last 10-12 days of every month

```{r warning=FALSE, message=FALSE, echo=FALSE}
fdata$hour=substr(fdata$datetime,12,13) #Positions Stripped
fdata$hour=as.factor(fdata$hour)

train=fdata[as.integer(substr(fdata$datetime,9,10))<20,]
test=fdata[as.integer(substr(fdata$datetime,9,10))>19,]

par(mfrow=c(2,2)) #Fill by rows: Row, Cols
par(mar = rep(2, 4)) #Setting Margins
boxplot(train$count~train$hour,xlab="hour", ylab="count of users", main = "Hourly Trend for All / General Users", col="red")
boxplot(train$registered~train$hour,xlab="hour", ylab="count of Registered users", main = "Hourly Trend for Registered Users", col="red")
boxplot(train$casual~train$hour,xlab="hour", ylab="count of Casual users", main = "Hourly Trend for Casual Users", col="red")
boxplot(log(train$count)~train$hour,xlab="hour",ylab="log(count)", main = "Hourly Trend on applying Log Transformation", col="red")
```

######Observation:

1. The General usage shall be classified into 3:
+ High: 7-9 and 17-19 hours
+ Medium: 10-16 hours
+ Low: 0-6 and 20-24 hours
2. The General Users' hourly trend is similar to the Registered Users' Hourly Trend
3. Existence of ***Natural Outliers*** 
to be treated with ***Logarathmic Transformations*** 
(taking the logarithm only works if the data is non-negative. Other transforms, 
such as ***arcsinh***, can be used to decrease data range if we have zero or negative values.)

######NOTE: Why Logarathmic Transformations?

1. It is generally a good idea to log transform data with values that range over several orders of magnitude. 2. Because Modeling techniques often have a difficult time with very wide data ranges
3. Because such data often comes from multiplicative processes, so log units are in some sense more natural.

#####6.2. Daily Trend - Bike Usage

```{r warning=FALSE, message=FALSE, echo=FALSE}
date=substr(fdata$datetime,1,10)
days<-weekdays(as.Date(date))
fdata$day=days

boxplot(fdata$registered~fdata$day,xlab="Week Days",ylab="Count of Users", main = "Daily Trend for Registered Users", col="orange")
boxplot(fdata$casual~fdata$day,xlab="Week Days",ylab="Count of Users", main = "Daily Trend for Casual Users", col="orange")
```

######Observation:

1. Demand for bikes by registered users are high on weekdays
2. Demand for bikes by casual users are high on weekends


#####6.3. Weather Patterns - Bike Usage

1. Weather 1: No Clouds
2. Weather 2: Partly Cloudy
3. Weather 3: Represents light rain
4. Weather 4: Represents heavy rain

```{r warning=FALSE, message=FALSE, echo=FALSE}
boxplot(fdata$registered~fdata$weather,xlab="Weather Conditions",ylab="Count of Users", main = "Weather Pattern for Registered Users", col="orange")
boxplot(fdata$casual~fdata$weather,xlab="Week Days",ylab="Count of Users", main = "Weather Pattern for Casual Users", col="orange")
```

######Observation:

1. Demand for bikes by all users are very low on rainy days
2. **Better Weather ~ High Demand**: Demand for bikes by all users is inversely proportional to the rain.

#####6.4. Temperature, Windspeed and Humidity - Bike Usage

These are continuous variables so we can look at the correlation factor to validate hypothesis.

```{r warning=FALSE, message=FALSE, echo=FALSE}
sub=data.frame(train$registered,train$casual,train$count,train$temp,train$humidity,train$atemp,train$windspeed)
# library(corrplot)
# cormat <- cor(Weekly[,-9])
# round(cormat, 2) # Rounded to 2 decimals

#corrplot(sub, method="circle", addCoef.col="black") 
#cor(sub)
sub <- cor(sub)
corrplot(sub, method="circle", addCoef.col="black") 
```

######Observation:

1. Highly Correlated:
+ Registered Users and General Users
+ Actual Temp or Temp and Casual Users
+ Humidity and Users (Negative Correlation)

2. Poorly Correlated:
+ Windspeed

#####6.5. Time - Bike Usage

```{r warning=FALSE, message=FALSE, echo=FALSE}
fdata$year=substr(fdata$datetime,1,4)
fdata$year=as.factor(fdata$year)
train=fdata[as.integer(substr(fdata$datetime,9,10))<20,]
test=fdata[as.integer(substr(fdata$datetime,9,10))>19,]
boxplot(train$count~train$year,xlab="year", ylab="count", main="Yearly Pattern of bike usage", col = "green")
```

######Observation:
2012 has higher bike demand than 2011.


####7. Feature Engineering

#####7.1. Hour Bins

```{r warning=FALSE, message=FALSE, eval=FALSE, echo=FALSE}
# # grow tree 
# fit <- rpart(Kyphosis ~ Age + Number + Start,
#   	method="class", data=kyphosis)
# 
# printcp(fit) # display the results 
# plotcp(fit) # visualize cross-validation results 
# summary(fit) # detailed summary of splits
# 
# # plot tree 
# plot(fit, uniform=TRUE, 
#   	main="Classification Tree for Kyphosis")
# text(fit, use.n=TRUE, all=TRUE, cex=.8)
# 
# # create attractive postscript plot of tree 
# post(fit, file = "c:/tree.ps", 
#   	title = "Classification Tree for Kyphosis")
```
```{r warning=FALSE, message=FALSE, echo=FALSE}
train$hour=as.integer(train$hour) # convert hour to integer
test$hour=as.integer(test$hour) # modifying in both train and test data set
fit=rpart(registered~hour,method = "anova", data=train)
#fancyRpartPlot(fit)

# plot tree 
plot(fit, uniform=TRUE, 
  	main="Classification Tree for Hourly Trend")
text(fit, use.n=TRUE, all=TRUE, cex=.8)

# create attractive postscript plot of tree 
post(fit, 
     file = "fit.ps", 
  	title = "Classification Tree for Classification for Hourly")
```

######**Making use of the splits and converting it into hourly bins for registered users**
```{r warning=FALSE, message=FALSE, echo=FALSE}
fdata=rbind(train,test)
fdata$dp_reg=0
fdata$dp_reg[fdata$hour<8]=1
fdata$dp_reg[fdata$hour>=22]=2
fdata$dp_reg[fdata$hour>9 & fdata$hour<18]=3
fdata$dp_reg[fdata$hour==8]=4
fdata$dp_reg[fdata$hour==9]=5
fdata$dp_reg[fdata$hour==20 | fdata$hour==21]=6
fdata$dp_reg[fdata$hour==19 | fdata$hour==18]=7
```


######**Making use of the splits and converting it into hourly bins for casual users**
```{r warning=FALSE, message=FALSE, echo=FALSE}
train$hour=as.integer(train$hour) # convert hour to integer
test$hour=as.integer(test$hour) # modifying in both train and test data set
fit=rpart(casual~hour,method = "anova", data=train)
#fancyRpartPlot(fit)

# plot tree 
plot(fit, uniform=TRUE, 
  	main="Classification Tree for Hourly Trend")
text(fit, use.n=TRUE, all=TRUE, cex=.8)
```

```{r warning=FALSE, message=FALSE, echo=FALSE}
#fdata=rbind(train,test)
fdata$dp_cas=0
fdata$dp_cas[fdata$hour<9]=1
fdata$dp_cas[fdata$hour>=9 & fdata$hour<11]=2
fdata$dp_cas[fdata$hour>=11 & fdata$hour<20.5]=3
fdata$dp_cas[fdata$hour>=20.5]=4
```

######**Making use of the splits and converting it into temperature wise bins**

```{r warning=FALSE, message=FALSE, echo=FALSE}
train$temp=as.integer(train$temp) # convert hour to integer
test$temp=as.integer(test$temp) # modifying in both train and test data set
fit=rpart(registered~temp,method = "anova", data=train)
#fancyRpartPlot(fit)

# plot tree 
plot(fit, uniform=TRUE, 
  	main="Classification Tree for Hourly Trend")
text(fit, use.n=TRUE, all=TRUE, cex=.8)

# create attractive postscript plot of tree 
post(fit, 
     file = "fit.ps", 
  	title = "Classification Tree for Classification for Hourly")
```

```{r warning=FALSE, message=FALSE, echo=FALSE}
#fdata=rbind(train,test)
fdata$temp_reg=0
fdata$temp_reg[fdata$temp<12]=1
fdata$temp_reg[fdata$temp>=12 & fdata$temp<20]=2
fdata$temp_reg[fdata$temp>=20 & fdata$temp<29]=3
```

######**Making use of the splits and converting it into temperature wise bins for Casual Users**

```{r warning=FALSE, message=FALSE, echo=FALSE}
train$temp=as.integer(train$temp) # convert hour to integer
test$temp=as.integer(test$temp) # modifying in both train and test data set
fit=rpart(casual~temp,method = "anova", data=train)
#fancyRpartPlot(fit)

# plot tree 
plot(fit, uniform=TRUE, 
  	main="Classification Tree for Hourly Trend")
text(fit, use.n=TRUE, all=TRUE, cex=.8)

# create attractive postscript plot of tree 
post(fit, 
     file = "fit.ps", 
  	title = "Classification Tree for Classification for Hourly")
```

```{r warning=FALSE, message=FALSE, echo=FALSE}
#fdata=rbind(train,test)
fdata$temp_cas=0
fdata$temp_cas[fdata$temp<15]=1
fdata$temp_cas[fdata$temp>=15 & fdata$temp<23]=2
fdata$temp_cas[fdata$temp>=23 & fdata$temp<30]=3
```




######**Making use of the splits and converting it into yearly-monthly bins**

Creating 8 bins (quarterly) for two years

```{r warning=FALSE, message=FALSE, echo=FALSE}
fdata$month=substr(fdata$datetime,6,7)
table(fdata$year, fdata$month)

fdata$year_part[fdata$year=='2011']=1
fdata$year_part[fdata$year=='2011' & fdata$month>3]=2
fdata$year_part[fdata$year=='2011' & fdata$month>6]=3
fdata$year_part[fdata$year=='2011' & fdata$month>9]=4
fdata$year_part[fdata$year=='2012']=5
fdata$year_part[fdata$year=='2012' & fdata$month>3]=6
fdata$year_part[fdata$year=='2012' & fdata$month>6]=7
fdata$year_part[fdata$year=='2012' & fdata$month>9]=8
table(fdata$year_part)
```

######**Making use of the splits and converting it into Day-Type bins**

Variable having categories like ???weekday???, ???weekend??? and ???holiday???.
```{r warning=FALSE, message=FALSE, echo=FALSE}
fdata$day_type=""
fdata$day_type[fdata$holiday==0 & fdata$workingday==0]="weekend"
fdata$day_type[fdata$holiday==1]="holiday"
fdata$day_type[fdata$holiday==0 & fdata$workingday==1]="working day"
table(fdata$day_type)
```

######**Making use of the splits and converting it into Weekend bins**

Separate variable for weekend (0/1)
```{r warning=FALSE, message=FALSE, echo=FALSE}
fdata$weekend=0
fdata$weekend[fdata$day=="Sunday" | fdata$day=="Saturday" ]=1
```


####8. Model Building

Before executing the random forest model code, I have followed following steps:

1. Convert discrete variables into factor (weather, season, hour, holiday, working day, month, day)
2. As we know that dependent variables have natural outliers so we will predict ***log of dependent variables***.
3. Predict bike demand registered and casual users separately. Here we have added 1 to deal with zero values in the casual and registered columns:
+ y1=log(casual+1) and 
+ y2=log(registered+1)

#####8.1. Predicting the log of registered users
```{r warning=FALSE, message=FALSE, echo=FALSE}
set.seed(415)
train$hour=as.factor(train$hour)
test$hour=as.factor(test$hour)

train$day=as.factor(train$day)
test$day=as.factor(test$day)






train=fdata[as.integer(substr(fdata$datetime,9,10))<20,]
test=fdata[as.integer(substr(fdata$datetime,9,10))>19,]
train$logreg <- log(train$registered+1)
# fit1 <- randomForest(logreg ~ hour +workingday+day+holiday+ day_type +temp_reg+humidity+atemp+windspeed+season+weather+dp_reg+weekend+year+year_part, data=train,importance=TRUE, ntree=250)
fit1 <- randomForest(logreg ~ hour + workingday + holiday + temp_reg
             + humidity + atemp + windspeed + season + weather
             + dp_reg + weekend + year +year_part, 
             data = train, importance=TRUE, ntree=250)
pred1=predict(fit1,test)
test$logreg=pred1
```

#####8.2. Predicting the log of Casual users

```{r warning=FALSE, message=FALSE, echo=FALSE}

set.seed(415)
train$logcas <- log(train$casual+1)
fit2 <- randomForest(logcas ~ hour + humidity + atemp + temp_cas + windspeed+ season+weather+holiday+workingday+dp_cas+weekend+year+year_part, data=train,importance=TRUE, ntree=250)
pred2=predict(fit2,test)
test$logcas=pred2
```

#####8.3. Re-transforming the predicted variables and then writing the output of count to the submission file 

```{r warning=FALSE, message=FALSE, echo=FALSE}
test$registered=exp(test$logreg)-1
test$casual=exp(test$logcas)-1
test$count=test$casual+test$registered
s<-data.frame(datetime=test$datetime,count=test$count)
s$count<- round(s$count) 
#write.csv(s,file="submit.csv",row.names=FALSE)
rm(list = ls())
#View(submit)
```

####9. Submission Format
```{r warning=FALSE, message=FALSE, echo=FALSE}
setwd('/Users/Mughundhan/Analytics Vidhya/Rental Biking')
submit <- read.csv("submit.csv", header=T, na.strings=c("","NA"))
head(submit)
final <- submit
#2011-01-20 00:00:00
# submit$datetime <- gsub("/", "-", submit$datetime)
# submit$datetime <- gsub("$", ":", submit$datetime)
# submit$datetime <- gsub("#", "x", submit$datetime)
# submit$datetime <- gsub("\"", "", submit$datetime)
# write.csv(submit,file="submit.csv",row.names=FALSE)
# write.csv2(submit,file="final.csv",row.names=FALSE)
library(lubridate)


submit$datetime <- as.character(submit$datetime)

submit$datetime <- dmy_hms(submit$datetime)
# calF <- as.Date(sapply(strsplit(calF,' '),'[',1),'%m/%d/%Y')
# submit$datetime1 <- ymd(submit$datetime1) + years(2000)
#write.csv(submit,file="final.csv",row.names=FALSE)

#final <- read.csv("final.csv", header=T, na.strings=c("","NA"))

head(submit)
rm(list = ls())

```